{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to database\n",
    "conn = psycopg2.connect(dbname='thingiscrape', user='robert', host='/tmp')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query database\n",
    "SQL = \"SELECT DISTINCT * FROM thingi_items ORDER BY item_id LIMIT(1000)\"\n",
    "c.execute(SQL)\n",
    "full_df = pd.DataFrame(c.fetchall(), columns = ['item_id','item_name','description','username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df['docs'] = full_df.pop('item_name') + ' ' + full_df.pop('description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>username</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>replicator</td>\n",
       "      <td>MakerBot Screwdriver It's a small screwdriver,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>replicator</td>\n",
       "      <td>MakerBot Plate It's an oblong sheet, about fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>replicator</td>\n",
       "      <td>MakerBot Hook It's a double-ended hook. Rather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>phooky</td>\n",
       "      <td>1st stellation of a dodecahedron This is a slo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>replicator</td>\n",
       "      <td>MakerBot Knob This is a small, slightly blocky...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id    username                                               docs\n",
       "0        2  replicator  MakerBot Screwdriver It's a small screwdriver,...\n",
       "1        3  replicator  MakerBot Plate It's an oblong sheet, about fou...\n",
       "2        5  replicator  MakerBot Hook It's a double-ended hook. Rather...\n",
       "3        7      phooky  1st stellation of a dodecahedron This is a slo...\n",
       "4        8  replicator  MakerBot Knob This is a small, slightly blocky..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext('local[4]')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_rdd = sc.parallelize(full_df['docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(numFeatures=1000)\n",
    "tf = hashingTF.transform(docs_rdd)\n",
    "\n",
    "idf = IDF().fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on IDFModel in module pyspark.mllib.feature object:\n",
      "\n",
      "class IDFModel(JavaVectorTransformer)\n",
      " |  Represents an IDF model that can transform term frequency vectors.\n",
      " |  \n",
      " |  .. versionadded:: 1.2.0\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      IDFModel\n",
      " |      JavaVectorTransformer\n",
      " |      pyspark.mllib.common.JavaModelWrapper\n",
      " |      VectorTransformer\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  idf(self)\n",
      " |      Returns the current IDF vector.\n",
      " |      \n",
      " |      .. versionadded:: 1.4.0\n",
      " |  \n",
      " |  transform(self, x)\n",
      " |      Transforms term frequency (TF) vectors to TF-IDF vectors.\n",
      " |      \n",
      " |      If `minDocFreq` was set for the IDF calculation,\n",
      " |      the terms which occur in fewer than `minDocFreq`\n",
      " |      documents will have an entry of 0.\n",
      " |      \n",
      " |      Note: In Python, transform cannot currently be used within\n",
      " |            an RDD transformation or action.\n",
      " |            Call transform directly on the RDD instead.\n",
      " |      \n",
      " |      :param x: an RDD of term frequency vectors or a term frequency\n",
      " |                vector\n",
      " |      :return: an RDD of TF-IDF vectors or a TF-IDF vector\n",
      " |      \n",
      " |      .. versionadded:: 1.2.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.mllib.common.JavaModelWrapper:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __init__(self, java_model)\n",
      " |  \n",
      " |  call(self, name, *a)\n",
      " |      Call method of java_model\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pyspark.mllib.common.JavaModelWrapper:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform names and descriptions\n",
    "# tfidfvect = TfidfVectorizer(stop_words='english', max_features = 1000)\n",
    "# documents_vec = full_df['item_name'] + ' ' + full_df['description']\n",
    "# vec_X = tfidfvect.fit_transform(documents_vec).toarray()\n",
    "# del documents_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_users_and_parts(user_ind, username):\n",
    "    # df_user_removed = df.drop(user_ind, axis = 0, inplace = False)\n",
    "    # X_user_removed = np.delete(X, user_ind, axis = 0)\n",
    "    n_items = 5\n",
    "\n",
    "    while True:\n",
    "        similar_users = []\n",
    "        similar_parts = []\n",
    "        base_ids = full_df.iloc[user_ind]['item_id']\n",
    "        \n",
    "        for i in user_ind:\n",
    "            # base_item = vec_X[i].reshape(1, -1)\n",
    "            base_item_id = full_df.iloc[i]['item_id']\n",
    "            # distances_vector = np.apply_along_axis(lambda x: cosine(x,base_item), 1, vec_X)\n",
    "            # distances_vector = linear_kernel(base_item, vec_X)\n",
    "            distances_vector = linear_kernel(vec_X[i:i+1], vec_X).flatten()\n",
    "            similar_indices = np.argsort(distances_vector)[::-1]\n",
    "            similar_items = full_df.iloc[np.ravel(similar_indices[:n_items])]\n",
    "\n",
    "            similar_users.extend(list(similar_items['username']))\n",
    "            similar_parts.extend(list(similar_items['item_id']))\n",
    "        \n",
    "        for item_id in base_ids:\n",
    "            if item_id in similar_parts:\n",
    "                similar_parts.remove(item_id)\n",
    "\n",
    "        similar_users_set = set(similar_users)\n",
    "        similar_parts_set = set(similar_parts)\n",
    "\n",
    "        similar_users_set.discard(username)\n",
    "\n",
    "        if len(similar_users_set) >= 5:\n",
    "            break\n",
    "        else:\n",
    "            n_items += 2\n",
    "\n",
    "    top_similar_users = sorted(similar_users_set, key = lambda x: similar_users.count(x), reverse = True)[:5]\n",
    "    top_similar_parts = sorted(similar_parts_set, key = lambda x: similar_parts.count(x), reverse = True)[:5]\n",
    "    return top_similar_users, top_similar_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "username = 'phooky'\n",
    "\n",
    "rec_start = time.time()\n",
    "print \"recommending!!!\"\n",
    "# username = str(request.form['user_input'])\n",
    "user_ind = np.ravel(np.argwhere(full_df['username']==username))\n",
    "print user_ind\n",
    "users, parts = get_top_users_and_parts(user_ind, username)\n",
    "rec_end = time.time()\n",
    "print \"time to recommend: {}\".format(rec_end-rec_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
